1:"$Sreact.fragment"
2:I[91320,["/_next/static/chunks/7b6121c01d7aa4a6.js","/_next/static/chunks/5ec360913fe0c25f.js","/_next/static/chunks/c4f32ce4dfee61b6.js","/_next/static/chunks/cff909f88976765f.js"],"PostList"]
10:I[97990,["/_next/static/chunks/28ff6a04602448ba.js","/_next/static/chunks/64c697a3cb51cd07.js"],"OutletBoundary"]
11:"$Sreact.suspense"
3:T29df,
# 기획자도 할 수 있다: AI 생성 & 슬랙 버튼으로 완성하는 E2E 테스트 자동화 파이프라인

프론트엔드 개발자로서 E2E(End-to-End) 테스트의 필요성은 절감하지만, 현실적인 장벽에 부딪힐 때가 많습니다.
"테스트 코드를 짤 시간이 없다", "QA팀은 코드를 모른다", "로컬에서 돌리기 번거롭다" 같은 이유들입니다.

오늘은 이 문제를 기술적으로 해결하기 위해 구축한 **"No-Code 생성 & ChatOps 실행"** 파이프라인을 소개합니다.

---

## 🏗️ 전체 시스템 아키텍처

우리가 만들 시스템의 흐름은 다음과 같습니다.

1.  **Creation (생성):**
    * **Method A (AI):** "로그인 후 메인으로 이동"이라고 적으면 GPT-4가 코드를 짜줍니다.
    * **Method B (Recorder):** 크롬 익스텐션을 켜고 클릭하면, 행동이 코드로 변환됩니다.
    * 결과물은 자동으로 GitHub PR로 등록됩니다.
2.  **Trigger (실행):** 슬랙의 "테스트 실행" 버튼을 누르면 AWS Lambda가 GitHub Actions를 깨웁니다.
3.  **Feedback (보고):** 테스트 결과가 **버튼을 눌렀던 그 스레드**에 답글로 달립니다.

---

## Part 1. 테스트 케이스 생성기 구축 (Server-side)

먼저 비개발자의 입력을 받아 Playwright 코드로 변환하고 PR을 날려주는 백엔드 API가 필요합니다. (Next.js API Route 기준 예시)

### 1-1. AI 기반 생성기 (Text-to-Code)

OpenAI API를 사용하여 자연어를 코드로 변환합니다.

**`pages/api/generate-from-text.ts`**

```typescript
import OpenAI from 'openai';
import { Octokit } from '@octokit/rest';

const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });
const octokit = new Octokit({ auth: process.env.GITHUB_TOKEN });

export default async function handler(req, res) {
  const { scenario, title } = req.body; // 예: "장바구니 담기 테스트"

  // 1. GPT-4에게 Playwright 코드 요청
  const completion = await openai.chat.completions.create({
    messages: [
      { 
        role: "system", 
        content: `You are a QA Engineer. Write a Playwright test script in TypeScript. 
                  Target URL is '[https://my-service.com](https://my-service.com)'. 
                  Use 'data-testid' selectors if possible. 
                  Only return the code block without markdown.` 
      },
      { role: "user", content: `Create a test for: ${scenario}` }
    ],
    model: "gpt-4-turbo",
  });
  
  const code = completion.choices[0].message.content;
  const branchName = `test/ai-${Date.now()}`;
  const fileName = `tests/${title}.spec.ts`;

  // 2. GitHub PR 생성 로직 (createPR 함수는 공통 모듈로 분리 권장)
  await createPullRequest(octokit, branchName, fileName, code, title);
  
  res.status(200).json({ success: true });
}

// GitHub PR 생성 헬퍼 함수
async function createPullRequest(octokit, branch, path, content, title) {
  const owner = "MY_ORG";
  const repo = "MY_REPO";

  // 메인 브랜치 SHA 조회
  const { data: refData } = await octokit.git.getRef({ owner, repo, ref: 'heads/main' });
  
  // 새 브랜치 생성
  await octokit.git.createRef({ owner, repo, ref: `refs/heads/${branch}`, sha: refData.object.sha });

  // 파일 커밋
  await octokit.repos.createOrUpdateFileContents({
    owner, repo, path, branch,
    message: `feat: add test case - ${title}`,
    content: Buffer.from(content).toString('base64')
  });

  // PR 생성
  await octokit.pulls.create({
    owner, repo, head: branch, base: 'main',
    title: `✅ [Auto-Gen] ${title}`
  });
}
```

### 1-2. Chrome Extension 기반 생성기 (Record & Push)

말로 설명하기 힘든 복잡한 시나리오는 직접 녹화하는 것이 빠릅니다.

#### A. 익스텐션 구조 (`manifest.json`)
```json
{
  "manifest_version": 3,
  "name": "E2E Recorder",
  "permissions": ["activeTab", "scripting"],
  "action": { "default_popup": "popup.html" },
  "content_scripts": [{ "matches": ["<all_urls>"], "js": ["content.js"] }]
}
```

#### B. 이벤트 수집기 (`content.js`)
웹페이지에 주입되어 클릭과 입력을 감지합니다.

```javascript
let events = [];

function getSelector(el) {
  if (el.getAttribute('data-testid')) return `[data-testid="${el.getAttribute('data-testid')}"]`;
  if (el.id) return `#${el.id}`;
  return el.tagName.toLowerCase(); // 실제론 더 정교한 path 로직 필요
}

document.addEventListener('click', (e) => {
  events.push({ type: 'click', selector: getSelector(e.target) });
}, true);

document.addEventListener('change', (e) => {
  events.push({ type: 'fill', selector: getSelector(e.target), value: e.target.value });
}, true);

chrome.runtime.onMessage.addListener((msg, sender, sendResponse) => {
  if (msg.action === "GET_EVENTS") sendResponse({ events });
});
```

#### C. 전송 및 변환 (`popup.js` & Backend)
팝업에서 '전송'을 누르면 백엔드로 이벤트를 보냅니다. 백엔드는 이를 코드로 바꿉니다.

**`pages/api/generate-from-record.ts`**

```typescript
export default async function handler(req, res) {
  const { events, title } = req.body;

  // JSON Events -> Playwright Code 변환
  let code = `import { test, expect } from '@playwright/test';\n\n`;
  code += `test('${title}', async ({ page }) => {\n`;
  
  events.forEach(evt => {
    if (evt.type === 'click') code += `  await page.click('${evt.selector}');\n`;
    if (evt.type === 'fill') code += `  await page.fill('${evt.selector}', '${evt.value}');\n`;
  });
  
  code += `});`;

  // GitHub PR 생성 (위와 동일한 로직)
  await createPullRequest(octokit, `test/record-${Date.now()}`, `tests/${title}.spec.ts`, code, title);
  
  res.status(200).json({ success: true });
}
```

---

## Part 2. 슬랙 트리거 & 중계 서버 (AWS Lambda)

이제 테스트 케이스가 준비되었습니다. 슬랙 버튼을 눌러 실행하는 환경을 만듭니다.
슬랙 인터랙션은 `application/x-www-form-urlencoded` 페이로드를 보내므로, 이를 받아 GitHub API(`application/json`)로 변환해줄 **중계 서버(Lambda)**가 필수적입니다.

**`index.js` (AWS Lambda Handler)**

```javascript
const { Octokit } = require("@octokit/rest");

exports.handler = async (event) => {
  // 1. 슬랙 Payload 파싱 (URL Decoding 필수)
  const bodyParams = new URLSearchParams(event.body);
  const payload = JSON.parse(bodyParams.get('payload'));

  // 2. 버튼 클릭 액션 감지
  if (payload.actions && payload.actions[0].action_id === "run_e2e_test") {
    const octokit = new Octokit({ auth: process.env.GITHUB_PAT });
    
    // 3. 핵심: 결과 리포팅을 위해 channel_id와 thread_ts 추출
    const channelId = payload.channel.id;
    const threadTs = payload.message.ts; // 메시지의 ts가 곧 스레드 ID가 됨

    try {
      // 4. GitHub Actions 트리거 (workflow_dispatch)
      await octokit.actions.createWorkflowDispatch({
        owner: "MY_ORG",
        repo: "MY_REPO",
        workflow_id: "e2e.yml",
        ref: "main",
        inputs: {
          slack_channel: channelId,
          slack_thread: threadTs, // 이 값을 GitHub로 넘겨주는 것이 제일 중요함!
        },
      });

      // 5. 슬랙 사용자 피드백 (즉시 응답)
      return {
        statusCode: 200,
        body: JSON.stringify({
          replace_original: false, // 기존 버튼 메시지 유지
          text: `🚀 테스트 요청이 접수되었습니다! (스레드를 확인하세요)`
        }),
      };
    } catch (error) {
      console.error(error);
      return { statusCode: 500, body: "GitHub API Error" };
    }
  }

  return { statusCode: 200, body: "OK" };
};
```

---

## Part 3. CI 실행 및 리포팅 (GitHub Actions)

마지막으로 GitHub Actions가 테스트를 수행하고, 넘겨받은 `slack_thread` 정보를 이용해 결과를 배달합니다.

### 3-1. 워크플로우 설정 (`.github/workflows/e2e.yml`)

```yaml
name: Playwright E2E
on:
  workflow_dispatch:
    inputs:
      slack_channel:
        required: true
      slack_thread:
        required: true

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v4
        with: { node-version: 20 }
      
      - name: Install Dependencies
        run: npm ci && npx playwright install --with-deps

      - name: Run Playwright
        run: npx playwright test
        continue-on-error: true # 테스트 실패해도 리포트는 보내야 하므로

      # 결과 전송 단계
      - name: Report to Slack
        if: always()
        env:
          SLACK_BOT_TOKEN: ${{ secrets.SLACK_BOT_TOKEN }}
          SLACK_CHANNEL: ${{ inputs.slack_channel }}
          SLACK_THREAD: ${{ inputs.slack_thread }}
          JOB_STATUS: ${{ job.status }}
        run: node scripts/report-to-slack.js
```

### 3-2. 리포팅 스크립트 (`scripts/report-to-slack.js`)

Webhook URL 방식은 스레드 답글이 불가능하므로, `slack-web-api`를 사용해야 합니다.

```javascript
const { WebClient } = require('@slack/web-api');
const web = new WebClient(process.env.SLACK_BOT_TOKEN);

async function report() {
  const channel = process.env.SLACK_CHANNEL;
  const thread_ts = process.env.SLACK_THREAD;
  const status = process.env.JOB_STATUS; // 'success' or 'failure'
  
  const isSuccess = status === 'success';
  const color = isSuccess ? '#36a64f' : '#ff0000';
  const icon = isSuccess ? '✅' : '❌';

  await web.chat.postMessage({
    channel: channel,
    thread_ts: thread_ts, // 람다 -> GitHub -> 여기까지 전달된 스레드 ID
    text: `E2E 테스트 결과: ${status}`,
    attachments: [
      {
        color: color,
        blocks: [
          {
            type: "section",
            text: {
              type: "mrkdwn",
              text: `${icon} *Playwright Test Completed*\nResult: *${status.toUpperCase()}*`
            }
          },
          {
            type: "context",
            elements: [{ type: "mrkdwn", text: "상세 로그는 GitHub Actions 탭을 확인하세요." }]
          }
        ]
      }
    ]
  });
}

report();
```

---

## 🎯 마치며

이렇게 구축된 환경에서 팀원들은 다음과 같이 일합니다.

1.  **생성:** 기획자가 "결제 페이지 테스트"를 입력하면 AI가 코드를 짜서 PR을 올립니다.
2.  **실행:** 슬랙 채널에 상주하는 "테스트 실행" 버튼을 누릅니다.
3.  **확인:** 커피 한 잔 하고 오면 **해당 스레드**에 초록색 체크(✅) 알림이 와 있습니다.

개발 환경 구축 없이 누구나 테스트에 기여할 수 있는 환경, 여러분의 팀에도 도입해 보세요.
4:Tfcc,
# E2E 테스트 vs 통합 테스트: 무엇이 다르고 어떻게 섞어 써야 할까?

테스트 코드를 작성하다 보면 항상 마주치는 고민이 있습니다.
*"이 기능을 통합 테스트로 짜야 할까, 아니면 E2E 테스트로 돌려야 할까?"*

결론부터 말하자면, 이 둘은 **양자택일(OR)의 문제가 아니라 상호 보완(AND)의 관계**입니다. 두 테스트는 검증하려는 '목적'과 바라보는 '관점' 자체가 다르기 때문입니다.

이번 포스팅에서는 헷갈리기 쉬운 두 테스트의 차이점을 명확히 정리하고, 어떻게 조합해야 효율적인지 이야기해 봅니다.

---

## 1. 통합 테스트 (Integration Test)
> **"모듈들이 합쳐졌을 때, 서로 대화가 잘 통하는가?"**

**통합 테스트**는 단위(Unit) 테스트보다 넓은 범위로, 개별적으로 잘 작동하는 컴포넌트나 모듈이 연결되었을 때 발생하는 인터페이스 문제를 잡아내는 것이 목적입니다.

* **관점:** **개발자(Developer)** 관점. 시스템 '내부'의 논리적 연결을 확인합니다.
* **특징:**
    * DB나 외부 API 같은 무거운 의존성은 **Mocking(가짜 데이터)** 처리를 하여 테스트 속도와 안정성을 확보하는 경우가 많습니다.
    * 단위 테스트보다는 느리지만, E2E보다는 훨씬 빠르고 비용이 저렴합니다.
* **주요 도구:** Jest, React Testing Library, Supertest, SpringBootTest 등

## 2. E2E 테스트 (End-to-End Test)
> **"실제 사용자가 사용하는 환경과 똑같이 작동하는가?"**

**E2E 테스트**는 말 그대로 '끝에서 끝까지', 사용자가 시스템을 사용하는 전체 흐름(Workflow)을 검증하는 단계입니다. 내부 코드가 어떻게 짜여 있는지는 신경 쓰지 않는 블랙박스(Black-box) 테스트입니다.

* **관점:** **최종 사용자(User)** 관점. 비즈니스 요구사항의 실제 동작 여부를 확인합니다.
* **특징:**
    * 실제 브라우저, 실제 DB, 네트워크 환경에서 테스트합니다. (Mocking 최소화)
    * 사용자에게 치명적인 버그(로그인 불가, 결제 실패 등)를 막는 최후의 보루입니다.
    * 실행 속도가 느리고, UI 변경에 민감하여 유지보수 비용이 높습니다.
* **주요 도구:** Cypress, Playwright, Selenium 등

---

## 3. 한눈에 보는 비교

| 구분 | 통합 테스트 (Integration Test) | E2E 테스트 (End-to-End Test) |
| :--- | :--- | :--- |
| **핵심 질문** | "모듈 간 데이터가 잘 흐르는가?" | "사용자가 목적을 달성할 수 있는가?" |
| **범위** | 여러 모듈의 집합 (외부 의존성 Mocking) | 시스템 전체 (프론트+백엔드+DB+인프라) |
| **신뢰도** | 논리적 연결성 보장 | 실제 사용자 경험(UX) 보장 |
| **속도** | 빠름 ~ 중간 | 느림 |
| **비용** | 중간 (작성/유지보수 용이) | 높음 (깨지기 쉬움) |

---

## 4. 결론: 어떻게 섞어 써야 할까? (Testing Pyramid)

모든 테스트를 E2E로 작성하면 신뢰도는 높겠지만, 배포 시간이 기하급수적으로 늘어나고 테스트가 자주 깨져 관리하기 힘들어집니다. 반대로 통합 테스트만 믿다가는 실제 환경에서의 예기치 못한 에러를 놓칠 수 있습니다.

따라서 일반적으로 권장되는 **'테스트 피라미드'** 전략을 따르는 것이 효율적입니다.

1.  **통합 테스트 (중간 비중):** 비즈니스 로직의 핵심 연결 고리를 검증하는 데 집중합니다. 다양한 예외 케이스는 주로 여기서 잡습니다.
2.  **E2E 테스트 (적은 비중):** 모든 것을 테스트하려 하지 말고, **가장 핵심적인 사용자 시나리오(Happy Path)**나 매출과 직결되는 기능(로그인, 결제, 장바구니 등) 위주로 구성합니다.

결국 좋은 테스트 전략이란 **"빠른 피드백(통합 테스트)"**과 **"확실한 안전망(E2E 테스트)"** 사이의 균형을 맞추는 것입니다.
5:T14d5,
# 🚀 Gemini CLI 완벽 가이드

Gemini CLI는 터미널에서 Google의 Gemini 모델과 직접 상호작용하며 코딩, 문서 작업, 시스템 관리 등을 수행할 수 있는 강력한 도구입니다.

## 1. 설정 (Configuration)

### 설치
Node.js 환경에서 npm을 통해 간단히 설치할 수 있습니다.

```bash
npm install -g @google/gemini-cli

# 또는 설치 없이 바로 실행하려면
npx @google/gemini-cli
```

### 인증 (Authentication)
설치 후 처음 실행하면 인증 절차가 진행됩니다.

```bash
gemini
```

* **Google 로그인 (권장):** 개인 사용자라면 브라우저를 통해 Google 계정으로 로그인하는 것이 가장 간편합니다.
* **API Key:** `GEMINI_API_KEY` 환경 변수를 설정하여 AI Studio에서 발급받은 키를 사용할 수 있습니다.
* **Vertex AI:** 기업/클라우드 사용자의 경우 `gcloud` 인증이나 서비스 계정을 통해 Vertex AI 모델을 사용할 수 있습니다.

### 설정 파일
Gemini CLI의 동작은 `settings.json` 파일을 통해 제어됩니다.

* **전역 설정:** `~/.gemini/settings.json`
* **프로젝트별 설정:** 프로젝트 루트의 `.gemini/settings.json` (이 설정이 전역 설정보다 우선함)
* **.env 파일 지원:** `.gemini/.env` 파일을 만들어 API 키나 프로젝트 ID 같은 환경 변수를 관리할 수 있습니다.

---

## 2. 기본 사용법 (Basic Usage)

Gemini CLI는 크게 **Slash 명령어(/)**, **At 명령어(@)**, **Shell 명령어(!)** 세 가지 방식으로 조작합니다.

### 🔹 Slash 명령어 (기능 제어)
CLI의 기능을 제어하거나 설정을 변경할 때 사용합니다.

* `/help`: 도움말 및 명령어 목록 확인
* `/clear` (또는 `Ctrl+L`): 화면 초기화
* `/chat save <태그>`: 현재 대화 상태 저장
* `/chat resume <태그>`: 저장된 대화 불러오기
* `/model`: 사용할 Gemini 모델 변경 (예: Gemini 1.5 Pro, Flash 등)
* `/settings`: 설정 메뉴 열기

### 🔹 At 명령어 (컨텍스트 주입)
파일이나 폴더의 내용을 프롬프트에 포함시킬 때 사용합니다.

* `@filename.js`: 특정 파일의 내용을 읽어 프롬프트에 추가
* `@src/`: 해당 디렉토리(및 하위 디렉토리)의 모든 텍스트 파일 내용을 추가
* `@README.md 이 파일을 요약해줘`: 파일 내용을 바탕으로 질문

### 🔹 Shell 명령어 (시스템 실행)
터미널 명령어를 직접 실행하거나 Gemini에게 실행을 맡길 수 있습니다.

* `!ls -la`: 현재 폴더 파일 목록 출력 (직접 실행)
* `!`: Shell 모드로 전환 (프롬프트가 쉘 명령어로 인식됨)

---

## 3. 잘 활용할 수 있는 팁 (Tips)

### 🛠 커스텀 커맨드 (Custom Commands) 만들기
자주 쓰는 복잡한 프롬프트를 단축키처럼 만들 수 있습니다. `.gemini/commands/` 폴더에 `.toml` 파일을 생성하여 정의합니다.

**예시: `/refactor` 명령어로 코드를 정리하도록 설정**
파일 경로: `~/.gemini/commands/refactor.toml`

```toml
description = "코드를 리팩토링하고 설명을 추가합니다."
prompt = """
다음 코드를 클린 코드 원칙에 따라 리팩토링해줘.
변경 사항에 대한 주석도 달아줘: {{args}}
"""
```
* **사용법:** `/refactor @main.js`

### ⌨️ 단축키 활용
* `Ctrl + L`: 화면 클리어
* `Ctrl + Z`: 입력 실행 취소 (Undo)
* `Ctrl + C`: 현재 작업 취소
* `Tab`: 자동 완성 수락

### 📂 프로젝트별 컨텍스트 관리 (GEMINI.md)
프로젝트 루트나 폴더에 `GEMINI.md` 파일을 만들고 프로젝트에 대한 설명, 코딩 컨벤션, 규칙 등을 적어두면 Gemini가 이를 "기억(Memory)"으로 인식하여 항상 해당 규칙을 따르며 답변합니다.

* **팁:** 컨벤션이 변경되었다면 `/memory refresh` 명령어로 `GEMINI.md` 내용을 갱신하세요.

### 🔧 내장 도구 (Tools) 활용
Gemini는 단순 텍스트 생성 외에도 실제 작업을 수행할 수 있는 도구들을 가지고 있습니다.

* `run_shell_command`: 쉘 명령어 실행 (예: "git status 확인해줘")
* `read_file` / `write_file`: 파일 읽기 및 생성/수정
* `web_fetch`: 특정 URL의 웹페이지 내용 긁어오기

---

## 4. 활용 예시 (Examples)

### 📸 이미지 파일 일괄 이름 변경
파일 내용을 인식하여 이름을 바꿔달라고 요청할 수 있습니다.
> **User:** "photos 폴더에 있는 이미지들의 내용을 보고 적절한 이름으로 변경해줘."
>
> **Gemini:** (각 이미지를 분석 후) `run_shell_command`를 사용하여 `mv photo1.jpg sunset_beach.jpg` 등의 명령을 제안하고 실행 승인을 요청함.

### 💻 오픈소스 코드 분석
방대한 코드를 빠르게 파악할 때 유용합니다.
> **User:** "`@src/` 폴더의 코드 구조를 파악하고, `app.js`가 어떻게 동작하는지 다이어그램을 그리듯이 설명해줘."

### 📊 데이터 병합 및 가공
> **User:** "`data_2023.csv`와 `data_2024.csv` 파일을 합치고, 매출 컬럼을 기준으로 내림차순 정렬해서 `total_sales.csv`로 저장해줘."

### 🧪 테스트 코드 자동 생성
> **User:** "`@login.ts` 파일을 읽고 이에 대한 Jest 유닛 테스트 코드를 작성해서 `login.test.ts` 파일로 만들어줘."
6:T1aeb,
# [가이드] Giscus: 광고 없는 무료 댓글 시스템, 5분 만에 적용하기

개발 블로그를 운영하다 보면 독자와의 소통을 위해 댓글 기능이 필요합니다. Disqus는 무겁고 광고가 많고, Utterances는 GitHub Issues를 사용해서 댓글이 이슈로 등록되는 부담이 있습니다.

이때 가장 좋은 대안이 바로 **Giscus**입니다. GitHub Discussions API를 활용하기 때문에 관리가 편하고, 디자인이 깔끔하며, 마크다운을 지원합니다.

## 1. 사전 준비 (GitHub 설정)

Giscus를 사용하려면 먼저 GitHub 저장소(Repository)가 준비되어 있어야 합니다.

1.  **Public Repository 생성**: 댓글을 저장할 저장소는 반드시 **Public**이어야 합니다. (블로그 소스 코드 저장소를 그대로 써도 되고, 댓글용 저장소를 따로 파도 됩니다.)
2.  **Giscus 앱 설치**: [GitHub Apps - Giscus](https://github.com/apps/giscus) 링크로 이동하여 `Install`을 클릭합니다. 위에서 준비한 저장소에 접근 권한을 허용해주세요.
3.  **Discussions 활성화**:
    * 해당 저장소의 **Settings** > **General** 탭으로 이동합니다.
    * `Features` 섹션에서 **Discussions** 체크박스를 켜서 활성화합니다.

## 2. 스크립트 생성 (설정값 추출)

[Giscus 공식 홈페이지](https://giscus.app/ko)로 이동하여 저장소 정보를 입력하면 자동으로 설정 코드를 만들어줍니다.

1.  **저장소(Repository) 입력**: `username/repo-name` 형식으로 입력합니다. (예: `my-id/my-blog-comments`)
    * *입력 후 로딩이 끝나면 아래 '페이지와 discussion 연결' 단계로 넘어갑니다.*
2.  **연결 방식 선택 (Page ↔ Discussion Mapping)**:
    * `pathname`: URL 경로를 기준으로 매칭 (추천, URL이 바뀌면 댓글도 새로 시작됨)
    * `og:title`: `<meta property="og:title">` 태그 내용 기준
    * 보통 블로그라면 `pathname`이 가장 무난합니다.
3.  **Discussion 카테고리 선택**:
    * 보통 `General`이나 `Announcements`를 선택합니다.
    * **주의**: 선택한 카테고리는 GitHub Discussions 탭에서 **누구나 글을 쓸 수 있는 권한**이 있어야 합니다. ("Announcements"는 관리자만 쓸 수 있는 경우가 많으니 권한 설정을 확인하거나 `General`을 추천합니다.)
4.  **기능 및 테마 선택**:
    * **메타데이터 전송**: 댓글 위에 페이지 정보를 표시할지 선택.
    * **테마**: 사이트 분위기에 맞춰 선택 (Light/Dark/Preferred Color Scheme 등).

## 3. 코드 적용하기

위 설정을 마치면 하단에 `<script>` 태그가 생성됩니다. 개발 환경에 맞춰 적용하세요.

### 방법 A: 일반 HTML / 정적 사이트 (Jekyll, Hugo 등)

생성된 스크립트 태그를 댓글이 표시될 위치(보통 포스트 하단)에 붙여넣기만 하면 됩니다.

```html
<script src="[https://giscus.app/client.js](https://giscus.app/client.js)"
        data-repo="[ENTER REPO HERE]"
        data-repo-id="[ENTER REPO ID HERE]"
        data-category="[ENTER CATEGORY NAME HERE]"
        data-category-id="[ENTER CATEGORY ID HERE]"
        data-mapping="pathname"
        data-strict="0"
        data-reactions-enabled="1"
        data-emit-metadata="0"
        data-input-position="bottom"
        data-theme="preferred_color_scheme"
        data-lang="ko"
        crossorigin="anonymous"
        async>
</script>
```

### 방법 B: React / Next.js (컴포넌트화)

React 환경에서는 `script` 태그를 직접 넣기보다 `useEffect`를 활용하거나 전용 컴포넌트를 만드는 것이 좋습니다. Next.js 등에서 라우팅 이동 시 댓글이 제대로 다시 로드되게 하려면 아래와 같이 작성합니다.

```tsx
// components/Giscus.tsx
import { useEffect, useRef } from 'react';

export default function Giscus() {
  const ref = useRef<HTMLDivElement>(null);

  // 테마가 바뀔 때 giscus 테마도 업데이트하려면 이 로직이 추가로 필요합니다.
  // const theme = useTheme(); // (프로젝트의 테마 hook 사용)

  useEffect(() => {
    if (!ref.current || ref.current.hasChildNodes()) return;

    const scriptElem = document.createElement('script');
    scriptElem.src = '[https://giscus.app/client.js](https://giscus.app/client.js)';
    scriptElem.async = true;
    scriptElem.crossOrigin = 'anonymous';

    // 설정값 주입 (giscus 웹사이트에서 생성된 값 복사)
    scriptElem.setAttribute('data-repo', '사용자명/저장소명');
    scriptElem.setAttribute('data-repo-id', 'R_kgDO...'); // ⚠️ 직접 생성된 값 확인 필수
    scriptElem.setAttribute('data-category', 'General');
    scriptElem.setAttribute('data-category-id', 'DIC_kwDO...'); // ⚠️ 직접 생성된 값 확인 필수
    scriptElem.setAttribute('data-mapping', 'pathname');
    scriptElem.setAttribute('data-strict', '0');
    scriptElem.setAttribute('data-reactions-enabled', '1');
    scriptElem.setAttribute('data-emit-metadata', '0');
    scriptElem.setAttribute('data-input-position', 'bottom');
    scriptElem.setAttribute('data-theme', 'preferred_color_scheme');
    scriptElem.setAttribute('data-lang', 'ko');

    ref.current.appendChild(scriptElem);
  }, []);

  // 테마 변경 동적 반영을 위한 postMessage (선택사항)
  // useEffect(() => {
  //   const iframe = document.querySelector<HTMLIFrameElement>('iframe.giscus-frame');
  //   iframe?.contentWindow?.postMessage({ giscus: { setConfig: { theme } } }, '[https://giscus.app](https://giscus.app)');
  // }, [theme]);

  return <section ref={ref} />;
}
```

## 4. 트러블 슈팅 & 꿀팁

1.  **403 Forbidden / Not Found 오류**:
    * `data-repo-id`와 `data-category-id`가 정확한지 확인하세요. (단순히 텍스트 이름이 아니라 GitHub API에서 할당된 고유 ID 값이어야 합니다. 공식 사이트 생성기에서 복사하는 것이 가장 확실합니다.)
    * Giscus 앱이 해당 저장소에 설치(Install)되어 있는지 확인하세요.
2.  **댓글이 안 보일 때**:
    * `giscus.json` 파일이 필요하지 않습니다. 저장소의 Discussions 탭에 실제로 'Giscus'라는 봇이 만든 discussion이 생성되는지 확인해보세요.
3.  **다크모드 대응**:
    * `data-theme="preferred_color_scheme"`을 사용하면 OS 설정에 따라 자동으로 변합니다.
    * 블로그 자체에 다크모드 토글이 있다면, 토글 이벤트 발생 시 `postMessage`를 보내 테마를 즉시 변경해 주는 것이 사용자 경험(UX)에 좋습니다.

---

**마무리하며**

Giscus는 GitHub 아이디만 있다면 누구나 쉽게 댓글을 남길 수 있고, 개발자 입장에서는 DB 관리 부담 없이 무료로 사용할 수 있는 최고의 솔루션입니다. 지금 바로 적용해 보세요!
7:T1460,
# GitHub Actions로 나만의 뉴스 브리핑 봇 만들기 (서버비 0원)

개발자라면 누구나 "최신 기술 트렌드를 놓치고 싶지 않다"는 욕망이 있습니다. 저 역시 여러 기술 블로그와 뉴스 사이트의 RSS를 구독하고 있습니다. 하지만 바쁜 일상 속에서 매번 RSS 리더기를 켜서 확인하는 것은 꽤나 번거로운 일입니다.

**"내가 가장 자주 보는 곳인 슬랙(Slack)으로, 새로운 뉴스가 뜰 때마다 알아서 배달해 준다면 어떨까?"**

이 아이디어를 실현하기 위해 별도의 서버 구축 없이, **GitHub Actions**만으로 동작하는 뉴스 브리핑 봇을 만들어 보았습니다.

---

## 1. 아키텍처 설계: 서버 없이 어떻게?

봇을 운영하려면 보통 24시간 돌아가는 서버가 필요하다고 생각하기 쉽습니다. 하지만 우리가 필요한 건 "1시간에 한 번" 정도의 주기적인 실행입니다. 이럴 때 **GitHub Actions**의 **Schedule(Cron)** 기능이 완벽한 대안이 됩니다.

### 핵심 도전 과제: "상태(State)" 저장
GitHub Actions는 실행될 때마다 환경이 초기화되는 "Stateless"한 특성을 가집니다. 즉, **"어디까지 뉴스를 읽었는지"** 기억할 방법이 필요합니다. 이를 위해 데이터베이스를 쓴다면 배보다 배꼽이 더 커지겠죠.

### 해결책: Git 저장소를 DB로 활용하기
저는 **파일 시스템(JSON)에 마지막 실행 시간을 기록하고, 이를 다시 Git에 커밋(Commit)하는 방식**을 선택했습니다.

1.  **Read:** `history.json` 파일을 읽어 마지막 실행 시간을 확인합니다.
2.  **Fetch:** RSS 피드에서 뉴스들을 가져옵니다.
3.  **Filter:** 마지막 실행 시간 이후에 발행된 글만 필터링합니다.
4.  **Notify:** 새로운 글을 슬랙으로 전송합니다.
5.  **Write & Commit:** 현재 시간을 `history.json`에 업데이트하고 저장소에 Push 합니다.

---

## 2. 구현하기 (Node.js)

### 패키지 구조
프로젝트의 모노레포 구조 내에 `packages/news-bot`이라는 별도 패키지를 만들었습니다.
필요한 라이브러리는 다음과 같습니다.
*   `rss-parser`: RSS XML 파싱
*   `axios`: 슬랙 웹훅 전송
*   `dayjs`: 날짜 계산

### 핵심 로직 (`index.ts`)

```typescript
// 핵심 로직 요약
async function main() {
  // 1. 마지막 실행 시간 로드
  const history = await getHistory(); // history.json 읽기
  const lastRun = dayjs(history.lastRun);

  // 2. RSS 피드 순회
  for (const feed of feeds) {
    const parsedFeed = await parser.parseURL(feed.url);
    
    // 3. 새로운 글 필터링
    const newItems = parsedFeed.items.filter(item => {
      return dayjs(item.pubDate).isAfter(lastRun);
    });

    // 4. 슬랙 전송
    for (const item of newItems) {
      await sendToSlack(feed.title, item);
    }
  }

  // 5. 상태 업데이트
  await saveHistory({ lastRun: dayjs().toISOString() });
}
```

---

## 3. GitHub Actions 설정 (Cron)

이제 이 스크립트를 주기적으로 실행해 줄 워크플로우(`news-bot.yml`)를 작성합니다.

```yaml
name: News Bot

on:
  schedule:
    - cron: '0 * * * *' # 매 시간 정각마다 실행
  workflow_dispatch: # 수동 실행 가능

jobs:
  run-news-bot:
    runs-on: ubuntu-latest
    permissions:
      contents: write # 저장소에 커밋하기 위해 쓰기 권한 필요

    steps:
      # ... (Node.js 설정 및 의존성 설치) ...

      - name: Run News Bot
        env:
          # GitHub Secrets & Variables 활용
          RSS_FEED_LIST: ${{ vars.RSS_FEED_LIST }}
          SLACK_RSS_WEBHOOK_URL: ${{ secrets.SLACK_RSS_WEBHOOK_URL }}
        run: |
          pnpm --filter @dev-holic/news-bot start

      - name: Commit and Push History
        run: |
          git config user.name "News Bot"
          git config user.email "bot@dev-holic.com"
          
          # history.json이 변경되었을 때만 커밋
          if [[ -n $(git status --porcelain packages/news-bot/history.json) ]]; then
            git add packages/news-bot/history.json
            git commit -m "chore(news-bot): update execution history [skip ci]"
            git push
          fi
```

### 팁: `[skip ci]`
커밋 메시지에 `[skip ci]`를 포함시키면, 이 커밋으로 인해 또 다른 CI/CD 파이프라인(예: 블로그 배포)이 불필요하게 트리거되는 것을 방지할 수 있습니다.

---

## 4. 결과 및 활용

이제 매시간 정각이 되면 봇이 깨어나 뉴스를 확인합니다. 새로운 글이 있다면 슬랙 채널에 다음과 같이 예쁘게 알림이 옵니다.

> **The Hacker News**
> [Hackers Using Fake Google Meet Pages to Deliver Malware](...)
> 2025-12-21 14:30

### 얻은 것들
1.  **비용 0원:** GitHub Actions 무료 티어 내에서 충분히 운용 가능합니다.
2.  **자동화된 정보 습득:** 내가 찾으러 다니지 않아도 정보가 나를 찾아옵니다.
3.  **확장성:** `RSS_FEED_LIST` 변수만 수정하면 구독 채널을 언제든 늘릴 수 있습니다.

여러분도 잠자고 있는 GitHub Actions를 깨워 나만의 비서로 활용해 보세요!
8:T139e,
# [Tip] RSS란 무엇인가? 내 기술 블로그에 RSS 달고 Feedly로 구독하기

기술 블로그를 운영하다 보면 "RSS 주소가 어떻게 되나요?"라는 질문을 받거나, 다른 개발자의 블로그를 효율적으로 구독하고 싶다는 생각이 들 때가 있습니다.

오늘은 정보의 홍수 속에서 나만의 뉴스 피드를 구축하게 해주는 **RSS의 개념**과, **GitHub Pages(Jekyll) 블로그에 RSS를 적용하는 방법**, 그리고 대표적인 리더기인 **Feedly 사용법**까지 A to Z로 정리해 드립니다.

---

## 1. RSS Feed란 무엇인가?

**RSS(Really Simple Syndication)**는 웹사이트의 콘텐츠 업데이트 정보를 사용자에게 자동으로 배달해주는 규약입니다. 쉽게 말해, 매일 아침 문 앞으로 배달되는 '신문'과 같습니다.

### 왜 필요한가요?
우리가 즐겨찾는 기술 블로그나 뉴스 사이트가 20군데 있다고 가정해 봅시다.
* **RSS가 없다면:** 매일 20군데 사이트를 일일이 들어가 "새 글이 올라왔나?" 확인해야 합니다. (비효율적)
* **RSS가 있다면:** 'RSS 리더'라는 앱 한 곳만 보면 됩니다. 새 글이 올라온 사이트의 콘텐츠만 쏙 뽑아서 모아 보여줍니다. (효율적)

### 핵심 장점
1.  **시간 절약:** 여러 사이트를 순회하는 시간을 줄여줍니다.
2.  **알고리즘 해방:** 유튜브나 SNS처럼 AI가 추천하는 글이 아니라, 내가 구독한 양질의 글을 시간 순서대로 빠짐없이 볼 수 있습니다.
3.  **광고 없는 읽기:** 웹사이트의 복잡한 레이아웃이나 광고 없이 본문 텍스트에만 집중할 수 있습니다.

---

## 2. 내 블로그에 RSS 적용하기 (GitHub Pages + Jekyll 예시)

GitHub Pages의 기본 엔진인 **Jekyll**을 사용하고 있다면, 플러그인 하나로 아주 쉽게 RSS Feed(`feed.xml`)를 생성할 수 있습니다.

### Step 1: `_config.yml` 설정
블로그 루트 디렉토리에 있는 `_config.yml` 파일을 열어 `plugins` 항목에 `jekyll-feed`를 추가합니다.

```yaml
# _config.yml

plugins:
  - jekyll-feed
```

### Step 2: `Gemfile` 확인
`Gemfile`에 `jekyll-feed` 플러그인이 포함되어 있는지 확인합니다. (GitHub Pages gem을 통째로 쓰고 있다면 생략해도 되지만, 명시해 주는 것이 좋습니다.)

```ruby
# Gemfile

group :jekyll_plugins do
  gem "jekyll-feed"
end
```
수정 후 터미널에서 `bundle install`을 실행하여 의존성을 설치합니다.

### Step 3: 로컬 테스트 및 배포
로컬 서버를 실행하여 정상적으로 xml 파일이 생성되는지 확인합니다.

```bash
bundle exec jekyll serve
```
브라우저 주소창에 `http://localhost:4000/feed.xml`을 입력했을 때, XML 코드가 가득한 페이지가 뜬다면 성공입니다. 이제 변경 사항을 GitHub에 `push` 하면 배포가 완료됩니다.

> **Tip:** 방문자가 RSS 주소를 쉽게 찾을 수 있도록 블로그의 사이드바나 푸터(Footer)에 RSS 아이콘을 추가하고 링크(`https://내블로그주소.com/feed.xml`)를 걸어주세요.

---

## 3. Feedly로 RSS 구독하고 관리하기

이제 내 블로그에도 RSS가 생겼고, 다른 좋은 기술 블로그들도 RSS를 지원합니다. 이를 한곳에서 모아보기 위해 가장 대중적인 리더기인 **Feedly(피들리)** 사용법을 알아봅시다.

### Step 1: 가입 및 로그인
[Feedly 공식 홈페이지](https://feedly.com)에 접속하여 구글, 애플, 트위터 등의 계정으로 가입합니다. (무료 플랜으로도 충분합니다.)

### Step 2: 구독 추가하기 (Follow)
1.  왼쪽 사이드바 메뉴에서 **'Follow Websites'** 또는 **'+'** 버튼을 클릭합니다.
2.  검색창에 **구독하고 싶은 블로그의 URL**이나 **RSS 주소**를 입력합니다.
    * *예: [https://techblog.woowahan.com](https://techblog.woowahan.com) (우아한형제들 기술블로그)*
3.  검색 결과에 해당 블로그가 뜨면 **'FOLLOW'** 버튼을 누릅니다.

### Step 3: 피드 분류하기 (Create Feed)
FOLLOW를 누르면 이 블로그를 어떤 폴더에 넣을지 묻습니다. 주제별로 폴더(Feed)를 만들어 관리하면 편리합니다.
* **Dev - Frontend** (프론트엔드 관련)
* **Dev - Corporate** (기업 기술 블로그)
* **Insight** (개발 외 인사이트)

### Step 4: 읽기
이제 매일 아침 Feedly 앱이나 웹사이트에 접속하기만 하면, 내가 구독한 모든 블로그의 최신 글들이 잡지처럼 정리되어 있습니다. 읽고 싶은 글을 클릭하여 편하게 읽으세요.

---

## 마치며

개발자에게 **최신 기술 트렌드 파악**과 **양질의 정보 습득**은 코딩 실력만큼이나 중요합니다. 오늘 당장 내 블로그에 RSS를 달아 독자들에게 편의를 제공하고, 나 또한 Feedly를 통해 나만의 지식 큐레이션 시스템을 만들어보는 건 어떨까요?

*Happy Coding & Happy Reading!*9:T169c,
개발팀이 성장하고 서비스 규모가 커지면 필연적으로 **'모니터링(Monitoring)'**에 대한 니즈가 발생합니다. 시장에는 수많은 툴이 있지만, 가장 대표적인 두 가지를 꼽자면 단연 **Datadog(데이터독)**과 **Sentry(센트리)**일 것입니다.

흔히 "둘 다 모니터링 툴 아니야?"라고 생각하기 쉽지만, 두 서비스는 **태생과 지향점**이 완전히 다릅니다. 이번 포스팅에서는 클라이언트, 서버 로깅, APM, RUM, 대시보드 구성 등을 기준으로 두 툴을 상세 비교하고, 어떤 상황에서 무엇을 선택해야 할지 정리해 보았습니다.

## 1. 핵심 철학의 차이: 관제실 vs 현미경

두 툴의 가장 큰 차이는 **'누구를 위해 만들어졌는가'**입니다.

* **Datadog:** 인프라 엔지니어와 DevOps를 위한 **통합 관제실**. 숲을 보고 시스템 전체의 이상 징후를 감지하는 데 특화되어 있습니다.
* **Sentry:** 애플리케이션 개발자를 위한 **디버깅 툴**. 나무를 보고 코드의 몇 번째 줄에서 에러가 났는지 분석하는 데 특화되어 있습니다.

---

## 2. 기능별 상세 비교

### ① 로깅 및 에러 트래킹 (Client & Server)

이 영역은 두 툴의 정체성이 가장 극명하게 갈리는 부분입니다.

| 구분 | Sentry (개발자 중심) | Datadog (운영자 중심) |
| :--- | :--- | :--- |
| **Client (FE/App)** | **압도적 우위.** Source Map을 통해 난독화된 코드의 정확한 위치를 집어줍니다. Breadcrumbs로 유저의 이동 경로 추적이 가능합니다. | 로그 수집은 가능하나, 프론트엔드 디버깅을 위한 직관적인 정보(Stack trace 시각화 등)는 부족합니다. |
| **Server Logging** | **Exception 중심.** 에러가 발생한 시점의 콜 스택 분석에 강력합니다. 단순 Info 로그를 쌓기엔 적합하지 않습니다. | **Log Management 강자.** 수십 기가의 로그를 쌓아두고 검색(Grep), 필터링, 시각화하는 능력이 탁월합니다. |
| **Grouping** | 같은 에러를 지능적으로 하나로 묶어주는 기능이 매우 뛰어납니다. | 패턴으로 묶을 수 있으나 Sentry만큼 정교한 이슈 관리는 어렵습니다. |

> **Key Point:** 프론트엔드/백엔드 **코드의 버그를 잡으려면 Sentry**가 필수적이고, 서버의 **전반적인 로그(접속 로그, 시스템 로그 등)를 관리하려면 Datadog**이 필요합니다.

### ② APM (Application Performance Monitoring)

* **Sentry:** **트랜잭션 중심**입니다. "이 API 호출이 왜 느리지?"를 코드 레벨에서 파고듭니다. 특정 함수나 DB 쿼리의 병목을 찾는 데 유용하며 설정이 비교적 간편합니다.
* **Datadog:** **인프라 + 트랜잭션**입니다. 코드 병목뿐만 아니라 CPU, 메모리, 네트워크, 디스크 I/O 등 인프라 지표와 연관 지어 분석합니다. 특히 MSA 환경에서 수십 개의 서비스가 얽혀있을 때의 **Service Map** 시각화 능력은 업계 표준 수준입니다.

### ③ RUM (Real User Monitoring) & Session Replay

* **Sentry:** **디버깅을 위한 UX 분석**에 가깝습니다. Core Web Vitals(LCP, FID) 측정에 충실하며, **Session Replay** 기능을 통해 유저가 에러를 겪은 순간의 화면을 녹화해서 보여줍니다. 이는 버그 재현에 엄청난 도움을 줍니다.
* **Datadog:** **비즈니스 인사이트 도출**까지 가능합니다. 사용자의 지역, 기기, 네트워크 상태 등 방대한 데이터를 수집합니다. Session Replay도 제공하지만, UX 분석 툴(Hotjar 등) 수준의 디테일과 마케팅적 데이터를 제공하는 대신 비용이 비쌉니다.

### ④ 대시보드 구성 (Customizability)

* **Sentry:** **낮은 자유도.** "할 일 목록(To-Do List)"에 가깝습니다. 이슈 목록, 릴리즈 현황 등 Sentry가 제공하는 뷰를 따라야 합니다. 개발자가 에러를 처리하는 워크플로우에 최적화되어 있습니다.
* **Datadog:** **높은 자유도.** NASA 관제실 같은 대시보드를 만들 수 있습니다. 로그 수, CPU 사용량, 심지어 매출액까지 원하는 모든 지표를 위젯으로 만들어 한 화면에 구성할 수 있습니다.

---

## 3. 가격 (Cost)

현실적으로 가장 중요한 부분입니다.

* **Sentry:** 상대적으로 합리적이고 예측 가능합니다. (사용자 수 + 이벤트 수 기반)
* **Datadog:** **비쌉니다.** 호스트 당, 로그 용량 당, APM 호스트 당, RUM 세션 당 과금이 따로 붙습니다. 자칫하면 요금 폭탄을 맞을 수 있어 핀옵스(FinOps) 관점의 관리가 필요합니다.

---

## 4. 결론: 무엇을 선택해야 할까?

### Sentry를 먼저 도입하세요, 만약...
* 서비스 초기~중기 단계이다.
* **프론트엔드(Web/App)** 의 비중이 크고 사용자 경험이 중요하다.
* "서버가 죽는 것"보다 "기능이 동작 안 하는 버그"가 더 큰 문제다.
* 개발자가 직접 모니터링하고 코드를 수정한다.

### Datadog이 필요합니다, 만약...
* 트래픽이 많고 **MSA(Microservices)** 구조로 인프라가 복잡하다.
* DevOps/SRE 팀이 별도로 존재한다.
* 비용보다 **안정성과 통합 관제**가 최우선이다.
* 규정상 로그를 장기간 보존하고 검색해야 한다.

### 💡 Best Practice
사실 예산이 허락한다면 **두 가지를 같이 쓰는 것이 가장 이상적**입니다.

* **Frontend & App:** Sentry (에러 잡기, 화면 녹화)
* **Backend & Infra:** Datadog (서버 상태, APM, 대량 로그)

각 툴의 강점이 명확한 만큼, 팀의 상황과 목적에 맞춰 적절한 도구를 선택하시길 바랍니다.
a:T29be,
1. 서론: 끝나지 않는 로딩의 미스터리

Next.js App Router는 서버 컴포넌트와 클라이언트 컴포넌트의 유연한 조합을 통해 강력한 웹 애플리케이션 구축을 가능하게 합니다. 하지만 이 새로운 렌더링 패러다임은 강력한 만큼, 기존의 클라이언트 중심 멘탈 모델과 충돌하며 흔한 함정을 만들어냅니다. 그 대표적인 사례가 바로 @tanstack/react-query의 useSuspenseQuery를 클라이언트 컴포넌트에서 사용했을 때 발생하는 '서버 행(Hanging)' 현상, 즉 페이지 응답이 멈추고 무한 로딩에 빠지는 문제입니다.

이 글은 이 문제를 단순한 버그가 아닌, 서버 우선 렌더링 모델과 클라이언트 데이터 페칭 패턴이 충돌할 때 발생하는 예측 가능한 결과로 분석합니다. 우리는 이 현상의 근본 원인을 명확히 파헤치고, next/dynamic을 활용해 의도적인 렌더링 경계를 설정하는 확실한 해결책을 제시할 것입니다. 이제 문제 상황을 구체적으로 재현하며 본격적인 분석을 시작하겠습니다.

2. 문제 현상 분석: useSuspenseQuery가 서버를 멈추게 할 때

모든 문제 해결의 첫걸음은 현상을 명확하게 정의하고 재현하는 것입니다. 정확한 진단 없이는 올바른 처방을 내릴 수 없기 때문입니다. 어떤 환경과 코드 구조에서 이 문제가 발생하는지 구체적으로 살펴보겠습니다.

문제는 다음과 같은 시나리오에서 발생합니다.

* 환경: Next.js App Router
* 구조: 서버 컴포넌트(Server Component)가 `<Suspense>` fallback UI로 클라이언트 컴포넌트(Client Component)를 감싸는 구조
* 핵심 원인: 감싸진 클라이언트 컴포넌트 내부에서 @tanstack/react-query의 useSuspenseQuery를 호출함

이 조건들이 충족될 때 나타나는 가장 명백한 증상은 다음과 같습니다. 페이지 응답이 완료되지 않고 브라우저 탭의 파비콘이 계속 로딩 상태로 남아있는 '서버 행(Hanging)' 현상이 발생합니다. 사용자는 아무런 콘텐츠도 보지 못한 채 끝없이 기다리게 되고, 개발자 도구의 네트워크 탭을 봐도 응답이 오지 않는 것을 확인할 수 있습니다.

이처럼 서버가 응답을 멈추는 현상은 왜 발생하는 것일까요? 이 근본적인 원인을 파헤치기 위해서는, 우리가 흔히 오해하는 클라이언트 컴포넌트의 렌더링 방식에 대한 정확한 이해가 필요합니다.

3. 근본 원인 탐구: 'use client'의 오해와 진실

단순히 현상을 해결하는 것을 넘어, Next.js App Router의 핵심 렌더링 메커니즘을 이해하는 것은 매우 중요합니다. 이번 문제의 근원은 바로 'use client' 지시어에 대한 흔한 오해에서 비롯됩니다.

'use client'는 CSR을 의미하지 않는다

많은 개발자가 'use client' 지시어를 파일 상단에 추가하면 해당 컴포넌트가 오직 브라우저에서만 렌더링(Client-Side Rendering, CSR)될 것이라고 생각합니다. 하지만 이는 사실이 아닙니다. 이 동작은 Next.js에 국한된 것이 아니라, React 18의 Suspense 기반 SSR의 고유한 특성입니다. 'use client'의 정확한 의미는 다음과 같습니다.

* Pre-rendering (사전 렌더링): 'use client'로 명시된 컴포넌트조차도, 최초 페이지 로드 시에는 서버에서 초기 HTML 뼈대를 미리 렌더링(Server-Side Rendering, SSR)합니다.
* Hydration (하이드레이션): 이후 브라우저에서 JavaScript 번들이 로드되면, 서버가 생성한 HTML 위에 이벤트 핸들러 등을 연결하여 상호작용이 가능한 완전한 컴포넌트로 '깨우는' 과정을 거칠니다.

즉, 별도의 설정이 없는 한 모든 클라이언트 컴포넌트는 서버에서 최소 한 번 실행됩니다. 바로 이 지점이 useSuspenseQuery가 서버 행을 유발하는 원인입니다. 그 메커니즘은 다음과 같습니다.

1. 서버 렌더링 시도: 사용자가 페이지에 접속하면, Next.js 서버는 UI를 구성하는 클라이언트 컴포넌트의 최초 HTML 렌더링을 시도합니다.
2. 데이터 부재와 Suspend: 서버 환경에는 react-query가 관리하는 클라이언트 측 캐시 데이터가 존재하지 않습니다. 따라서 useSuspenseQuery는 데이터를 가져오기 위해 Promise를 던지고(throw), 컴포넌트를 'Suspend(일시 중단)' 상태로 만듭니다.
3. 무한 대기: 서버에 있는 부모 `<Suspense>` 경계가 이 Promise를 감지합니다. 이는 Next.js 서버의 렌더러에게 "이 부분의 HTML 생성을 중단하고 Promise가 해결될 때까지 기다려라"는 신호입니다. 하지만 이 Promise는 클라이언트 사이드 데이터 페칭 로직이므로 서버에서는 절대 해결될 수 없습니다. 결과적으로, Next.js 서버의 응답 스트림 전송이 중단된 채 무기한 대기하게 되는 '행(Hanging)' 상태에 빠집니다.

결국 문제의 원인은 클라이언트에서만 실행되어야 할 데이터 페칭 로직이 서버 렌더링 과정 중 시도되었기 때문입니다. 이를 해결하기 위한 전략은 명확합니다. 해당 컴포넌트의 서버 렌더링 자체를 의도적으로 비활성화하는 것입니다.

4. 해결책 제시: next/dynamic과 ssr: false 옵션

문제의 원인이 서버 렌더링 시도에 있다는 것을 파악했으니, 이제 명확한 해결책을 제시할 차례입니다. 우리는 해당 컴포넌트를 기본 SSR/Hydration 모델에서 의도적으로 제외하고, 순수한 클라이언트 사이드 렌더링(CSR) 경계를 설정해야 합니다.

이때 사용할 수 있는 가장 강력한 도구가 바로 Next.js의 내장 기능인 next/dynamic입니다. next/dynamic은 컴포넌트를 동적으로 임포트하게 해주며, 특히 ssr: false 옵션과 함께 사용될 때 이 문제의 완벽한 해결책이 됩니다.

ssr: false 옵션의 역할은 매우 직관적입니다. 이것은 Next.js 서버에게 **"이 컴포넌트의 HTML은 미리 만들지 말고, 브라우저에서 JavaScript가 로드된 후에 렌더링을 시작하라"**고 명확히 지시하는 것과 같습니다.

이 해결책을 적용했을 때 얻게 되는 결과는 다음과 같습니다.

* 서버는 해당 컴포넌트의 렌더링을 완전히 건너뛰고 나머지 페이지의 HTML을 구성하여 즉시 클라이언트에 응답을 보냅니다.
* 클라이언트(브라우저)는 초기 HTML을 받은 후, 해당 컴포넌트의 JavaScript 코드를 비동기적으로 로드합니다.
* 로드가 완료되면, 실제 데이터 페칭(useSuspenseQuery)과 렌더링은 온전히 클라이언트 환경에서만 일어나므로 서버 행 이슈가 근본적으로 해결됩니다.

이론적 설명을 마쳤으니, 이제 실제 코드를 통해 이 해결책을 어떻게 적용하는지 구체적으로 살펴보겠습니다.

5. 적용 코드 예시: 문제 해결의 실제

앞서 설명한 해결책을 실제 코드에 어떻게 적용하는지 보여드리겠습니다. 부모인 서버 컴포넌트에서 useSuspenseQuery를 사용하는 자식 클라이언트 컴포넌트를 불러오는 방식을 어떻게 변경하는지 집중해서 보시기 바랍니다.

먼저 부모 컴포넌트인 **ServerComponent.tsx**의 변경 사항입니다. import 구문을 next/dynamic으로 대체하고 ssr: false 옵션을 추가합니다.

```typescript
// ServerComponent.tsx (부모 컴포넌트)
import dynamic from 'next/dynamic';

// 핵심: ssr: false 옵션으로 서버 렌더링을 비활성화
const ClientComponentWithNoSSR = dynamic(
  () => import('./ClientComponent'),
  {
    ssr: false,
    // 컴포넌트의 JS가 로드되는 동안 보여줄 UI
    loading: () => <p>Loading...</p>,
  }
);

export default function Page() {
  return (
    <div>
      <h1>My Page</h1>
      {/* 서버 행 이슈 없이 클라이언트에서만 렌더링됩니다. */}
      <ClientComponentWithNoSSR />
    </div>
  );
}
```


다음은 **ClientComponent.tsx**의 코드입니다. 흥미롭게도 이 컴포넌트의 코드는 전혀 변경할 필요가 없습니다. next/dynamic을 통해 렌더링 제어의 책임이 부모 컴포넌트로 넘어갔기 때문입니다.

```typescript
// ClientComponent.tsx (자식 컴포넌트)
'use client';

import { useSuspenseQuery } from '@tanstack/react-query';

// 임의의 데이터 fetch 함수
async function fetchData() {
  // 실제 네트워크 딜레이를 시뮬레이션
  await new Promise(resolve => setTimeout(resolve, 1000));
  // ... API 호출 로직 ...
  return { title: 'Fetched Data on Client!' };
}

export default function ClientComponent() {
  // 이 코드는 이제 ssr: false 덕분에 클라이언트에서만 실행되므로 안전합니다.
  const { data } = useSuspenseQuery({
    queryKey: ['data'],
    queryFn: fetchData
  });

  return <div>{data.title}</div>;
}
```


코드 예시를 통해 해결 방법이 얼마나 간단하고 명확한지 확인하셨을 것입니다. 이제 마지막으로 이 경험을 통해 얻을 수 있는 중요한 교훈을 정리해 보겠습니다.

6. 결론: App Router 렌더링 전략의 이해

useSuspenseQuery와 클라이언트 컴포넌트 조합 사용 시 발생한 서버 행 이슈는 단순한 버그가 아닙니다. 이는 Next.js App Router가 채택한 렌더링 모델에 대한 깊은 이해가 왜 중요한지를 보여주는 매우 좋은 사례이며, 의도적인 렌더링 경계 설계의 필요성을 역설합니다.

이 글을 통해 우리가 얻은 핵심 교훈은 다음과 같습니다.

* 핵심 교훈 1: 'use client'는 서버 렌더링을 배제하는 지시어가 아닙니다. 이는 서버에서 사전 렌더링 후 클라이언트에서 하이드레이션하는, 즉 SSR과 CSR이 결합된 App Router의 기본 모델을 의미합니다.
* 핵심 교훈 2: 만약 컴포넌트가 서버 환경에서는 실행되어서는 안 되는 클라이언트 전용 데이터 페칭 로직이나 API를 포함하고 있다면, next/dynamic과 ssr: false 옵션을 사용하는 것은 단순한 문제 해결이 아닌, 필수적인 아키텍처 결정입니다. 이를 통해 명확한 CSR 경계를 설정해야 합니다.

이제 여러분은 Next.js의 렌더링 전략을 더 효과적으로 활용할 준비가 되었습니다. 이 글에서 다룬 원리와 해결책을 바탕으로 유사한 문제를 예방하고, 더욱 견고하고 안정적인 애플리케이션을 구축하시기를 바랍니다.b:T18cd,
# 프론트엔드 개발, OOP와 FP의 완벽한 조화: 실무 적용 가이드

프론트엔드 개발 생태계는 빠르게 변화했습니다. 과거 UI를 클래스로 제어하던 시절을 지나, React Hooks와 Redux의 등장으로 함수형 프로그래밍(FP)의 개념이 깊숙이 자리 잡았습니다.

많은 개발자가 **"그래서 클래스를 써야 해, 함수를 써야 해?"**라는 질문을 던집니다. 하지만 모던 프론트엔드 아키텍처의 핵심은 양자택일이 아닌 **적재적소의 조화(Harmony)**에 있습니다.

이번 포스팅에서는 프론트엔드 실무에서 **객체 지향 프로그래밍(OOP)**과 **함수형 프로그래밍(FP)**을 어떻게 섞어 써야 가장 효율적인지, 구체적인 케이스와 코드를 통해 알아봅니다.

---

## 1. 객체 지향 프로그래밍 (OOP)
> **핵심 키워드:** 캡슐화(Encapsulation), 상태 유지, 응집도

OOP는 데이터(State)와 그 데이터를 조작하는 행위(Method)를 하나의 '객체'로 묶어서 관리합니다. 프론트엔드에서 OOP가 빛을 발하는 순간은 **"맥락(Context)을 유지해야 할 때"**입니다.

### 📌 Best Case: 외부 시스템 및 연결 관리 (Service Layer)
API 클라이언트, 소켓 연결, 복잡한 인증 로직처럼 **설정값이나 연결 상태를 계속 유지해야 하는 경우** 클래스가 유리합니다.

#### ❌ FP만 고집할 때의 문제점 (Prop Drilling)
모든 함수에 토큰이나 설정값을 인자로 계속 넘겨줘야 합니다.

```typescript
// 매번 token을 인자로 받아야 함 (불편함)
const fetchUser = (token: string, userId: string) => {
  return fetch(`/api/users/${userId}`, {
    headers: { Authorization: token }
  });
};
```

#### ✅ OOP를 활용한 해결책 (Encapsulation)
`ApiClient` 클래스 내부에 토큰과 Base URL을 **캡슐화**하면, 사용하는 쪽에서는 내부 구현을 신경 쓸 필요가 없습니다.

```typescript
class ApiClient {
  constructor(private token: string, private baseUrl: string) {}

  // 설정값(token)을 내부 상태로 관리하여 응집도를 높임
  private async request(path: string) {
    return fetch(`${this.baseUrl}${path}`, {
      headers: { Authorization: this.token }
    });
  }

  getUser(userId: string) {
    return this.request(`/users/${userId}`);
  }
}

// 사용: 사용하는 쪽 코드가 깔끔해짐
const api = new ApiClient('user-token-123', 'https://api.app.com');
api.getUser('user-1'); // 토큰을 넘길 필요 없음
```

---

## 2. 함수형 프로그래밍 (FP)
> **핵심 키워드:** 순수 함수(Pure Function), 불변성(Immutability), 파이프라인

FP는 부수 효과(Side-effect)를 없애고 입력이 같으면 출력도 같다는 것을 보장합니다. 프론트엔드에서 FP가 빛을 발하는 순간은 **"데이터를 가공하고 계산할 때"**입니다.

### 📌 Best Case: 비즈니스 로직 및 데이터 변환
서버에서 받은 데이터를 필터링하거나, 장바구니 합계를 계산하는 등의 로직은 순수 함수로 작성하는 것이 좋습니다.

#### ❌ OOP 스타일의 문제점 (강한 결합)
로직이 특정 객체의 상태(`this`)에 의존하면, 테스트하기 어렵고 다른 곳에서 재사용하기 힘듭니다.

```typescript
class ShoppingCart {
  private items: Product[] = [];
  
  // 상태와 로직이 섞여 있어 테스트가 번거로움
  calculateTotal() {
    return this.items.reduce((sum, item) => sum + item.price, 0);
  }
}
```

#### ✅ FP를 활용한 해결책 (Predictability)
데이터 구조와 로직을 분리합니다. `calculateTotal` 함수는 오직 입력받은 배열에만 의존하므로 예측 가능하고 테스트가 쉽습니다.

```typescript
// 순수 함수: Input -> Output이 명확함
const calculateTotal = (items: Product[]): number => {
  const total = items.reduce((sum, item) => sum + item.price, 0);
  // 배송비 계산 로직 등 확장에도 유연함
  return total > 30000 ? total : total + 3000;
};

// 사용: 어디서든 재사용 가능
const finalPrice = calculateTotal(cartItems);
```

---

## 3. 결론: 하이브리드 아키텍처 (Harmony)

실제 프로덕션 레벨의 프론트엔드 코드는 이 두 가지 패러다임을 혼합하여 사용합니다. React 컴포넌트는 이 둘을 이어주는 **접착제(Glue)** 역할을 수행합니다.

### 💡 실무 적용 패턴 예시

1.  **OOP:** 복잡한 API 통신과 설정은 `Class`로 관리합니다.
2.  **FP:** 데이터를 화면에 보여주기 위한 가공은 `Pure Function`을 사용합니다.
3.  **React:** 이 둘을 조합하여 UI를 렌더링합니다.

```tsx
// 1. [OOP] Service Layer 인스턴스 생성
const authService = new AuthService(config);

const UserList = () => {
  const [users, setUsers] = useState([]);

  useEffect(() => {
    // [OOP] 메서드 호출: 복잡한 인증 로직은 숨겨져 있음
    authService.getUsers().then(setUsers);
  }, []);

  // 2. [FP] 순수 함수 사용: 데이터 가공 로직 분리
  // sortUsersByName은 외부 파일에 정의된 순수 함수라고 가정
  const sortedUsers = useMemo(() => sortUsersByName(users), [users]);

  return (
    <ul>
      {/* 3. [FP] 선언적 렌더링 */}
      {sortedUsers.map(user => (
        <li key={user.id}>{user.name}</li>
      ))}
    </ul>
  );
};
```

### 요약: 언제 무엇을 써야 할까?

| 구분 | 역할 | 추천 패러다임 | 이유 |
| :--- | :--- | :--- | :--- |
| **API / Service** | 데이터 페칭, 소켓, 인증 | **OOP** | 설정값과 연결 상태를 **캡슐화**하기 위해 |
| **Business Logic** | 계산, 포맷팅, 필터링 | **FP** | **테스트 용이성**과 예측 가능성을 위해 |
| **Store** | 전역 상태 변경 (Redux 등) | **FP** | **불변성**을 통한 상태 변경 추적을 위해 |
| **UI Component** | 화면 렌더링 | **Hybrid** | 라이프사이클(OOP) + 렌더링 로직(FP) |

프론트엔드 개발자로서 한 가지 패러다임에 갇히기보다, 각 패러다임이 가진 장점을 이해하고 상황에 맞게 골라 쓰는 유연함이 필요합니다. 

**"상태 관리는 OOP처럼, 데이터 처리는 FP처럼."** 이 원칙을 기억하면 더 견고한 애플리케이션을 설계할 수 있을 것입니다.
c:T13dd,
# 무조건적인 가상화(Virtualization) 도입, 과연 정답일까? (feat. content-visibility)

프론트엔드 개발자라면 긴 리스트를 다룰 때 습관적으로 **"가상화(Virtualization)를 도입해야겠다"**고 생각합니다. `react-window`나 `tanstack-virtual` 같은 라이브러리를 설치하는 것이 일종의 'Best Practice'처럼 여겨지죠.

하지만 10년 차 프론트엔드 개발자로서 수많은 프로젝트를 거치며 깨달은 점은, **가상화는 공짜 점심이 아니라는 사실**입니다. 가상화는 성능을 얻는 대신 **UX(사용자 경험)**를 비용으로 지불합니다.

오늘은 리스트 렌더링 성능 최적화의 본질적인 원리와, 가상화가 가진 UX 결함, 그리고 이를 대체할 수 있는 모던 CSS 전략(`content-visibility`)에 대해 이야기해보려 합니다.

---

## 1. 우리는 왜 가상화를 하는가? (본질적인 병목)

데이터가 수천, 수만 개로 늘어날 때 브라우저가 느려지는 진짜 이유는 무엇일까요? 단순히 "데이터가 많아서"가 아닙니다.

### DOM 개수의 비대화와 선형적 성능 저하
가장 큰 문제는 DOM 노드의 개수입니다. 리스트 아이템이 1만 개이고, 각 아이템이 10개의 태그를 가진다면 브라우저는 **10만 개의 DOM 노드**를 메모리에 올리고 관리해야 합니다.

문제는 사용자가 스크롤을 내려 페이지가 쌓일수록 성능 저하가 **선형적(Linear)**으로 발생한다는 점입니다.
* **Recalculate Style 비용 증가:** 버튼 하나를 클릭해 상태가 바뀌어도, 브라우저는 거대해진 DOM 트리를 순회하며 스타일 계산을 다시 해야 합니다.
* **메모리 누수:** 화면 밖으로 지나간 수천 개의 이미지와 컴포넌트들이 메모리(RAM/VRAM)를 계속 점유합니다.

가상화(Virtualization)는 이 문제를 해결하기 위해 **"보이는 영역(Viewport)만 렌더링하고, 벗어난 영역은 DOM에서 제거"**하는 기술입니다. 덕분에 데이터가 100만 개여도 DOM 노드는 항상 20개 내외로 유지됩니다.

---

## 2. 오해: "스크롤하면 리페인트(Repaint)가 발생해서 느리다?"

많은 개발자가 *"DOM이 많으면 스크롤할 때마다 리페인트가 발생해서 느리다"*고 오해합니다. 결론부터 말하면 **최신 브라우저에서 최적화된 네이티브 스크롤은 리페인트를 유발하지 않습니다.**

### 브라우저의 스크롤 동작 원리 (Pixel Pipeline)
1.  **Composite Only:** 브라우저는 스크롤 가능한 영역을 별도의 **레이어(Layer)**로 승격(Promote)시킵니다.
2.  **GPU 가속:** 이미 그려진(Paint 완료된) 비트맵 텍스처를 GPU가 좌표만 이동시킵니다.
3.  **결과:** Layout과 Paint 단계를 건너뛰고 **Composite** 단계만 수행하므로 매우 부드럽습니다.

### 그렇다면 가상화 없는 1만 개 리스트는 왜 버벅거릴까?
리페인트 때문이 아니라, 다른 연산 비용 때문입니다.
1.  **Hit Testing 과부하:** 스크롤 중 마우스 커서 아래에 어떤 요소가 있는지(Hover, Event 등) 계산해야 하는데, DOM이 1만 개면 이 탐색 비용이 16ms(60fps)를 초과합니다.
2.  **GPU 대역폭 한계:** 1만 개 분량의 거대한 텍스처를 타일링(Tiling)하고 GPU 메모리로 전송하는 과정에서 병목이 발생합니다.
3.  **GC(가비지 컬렉션):** 수많은 DOM 노드 참조로 인해 GC 수행 시간이 길어져 스크롤이 턱턱 걸리게 됩니다.

아이러니하게도, **가상화를 적용하면 스크롤할 때마다 필연적으로 리페인트가 발생**합니다. JS가 DOM을 계속 갈아 끼우기 때문이죠. 하지만 "전체 DOM을 유지하는 비용"보다 "작은 영역을 계속 다시 그리는 비용"이 훨씬 싸기 때문에 가상화를 쓰는 것입니다.

---

## 3. 가상화의 치명적인 단점 (UX Trade-offs)

성능을 위해 가상화를 도입하면 다음과 같은 UX 손해를 감수해야 합니다.

1.  **Ctrl + F (검색) 불가:** DOM에 요소가 없으니 브라우저 기본 찾기 기능으로 내용을 찾을 수 없습니다.
2.  **스크롤 이질감:** 네이티브 스크롤의 관성, 바운스 등을 JS로 흉내 내야 하므로 미묘하게 어색합니다.
3.  **스크롤바 널뛰기:** 동적 높이(Dynamic Height) 아이템일 경우, 스크롤바가 떨리거나 위치가 튀는 현상이 발생합니다.
4.  **빈 화면(White Space):** 스크롤 속도가 렌더링 속도보다 빠르면 하얀 빈 공간이 보입니다.

---

## 4. 현실적인 대안: CSS `content-visibility`

"데이터가 100~200개 정도인데 가상화를 써야 할까?"
이런 고민이 든다면, 가상화는 오버엔지니어링일 확률이 높습니다. 이때 사용할 수 있는 강력한 대안이 CSS의 **`content-visibility: auto`** 입니다.

```css
.list-item {
  content-visibility: auto;
  contain-intrinsic-size: 100px; /* 아이템의 예상 높이 */
}

```
d:T1f43,
# [Architecture] NPM 패키지 분리 환경에서 싱글톤(Singleton) 유지하기: globalThis와 Symbol.for의 활용

최근 사내 패키지 배포 구조를 개선하면서 마주친 문제와 그 해결 과정을 공유합니다.

여러 프로젝트에서 공통으로 사용하는 패키지들을 npm 저장소(Nexus 등)에 배포하여 관리하고 있는데, 배포 편의성을 위해 의존성 패키지를 번들(Bundle)에 포함시키는 과정에서 **싱글톤(Singleton) 객체가 유지되지 않는 이슈**가 발생했습니다.

이 글에서는 물리적으로 분리된 번들 환경에서 어떻게 안전하게 싱글톤 인스턴스를 공유했는지, 그 과정에서 **`globalThis`**와 **`Symbol.for`**를 어떻게 활용했는지 다룹니다.

## 1. 문제 상황 (The Problem)

### 아키텍처 구조
현재 우리 팀은 다음과 같은 3가지 패키지를 운용하고 있습니다.

* **Framework**: 핵심 로직과 싱글톤 객체(Store, Manager 등)를 제공
* **Editor**: `Framework`를 의존하여 사용하는 편집 도구
* **Converter**: `Framework`를 의존하여 사용하는 변환 도구

배포 및 설치 편의성을 위해 `Editor`와 `Converter`를 배포할 때, 이들이 의존하는 `Framework` 코드를 각각의 번들에 포함(Bundled)시켜 배포했습니다.

### 발생한 이슈
호스트 애플리케이션에서 `Editor`와 `Converter`를 동시에 설치해서 사용할 때 문제가 발생했습니다.

1.  `Editor`가 로드되면서 내부의 `Framework`가 초기화됨 (싱글톤 A 생성)
2.  `Converter`가 로드되면서 내부의 `Framework`가 초기화됨 (싱글톤 B 생성)
3.  **결과:** 두 패키지가 **서로 다른 싱글톤 인스턴스**를 바라보게 되어 상태 공유가 불가능해짐.

## 2. 원인 분석

일반적인 ES Module 시스템에서 싱글톤은 **모듈 스코프(Module Scope)** 내의 클로저를 통해 유지됩니다.

하지만 번들링을 하게 되면 각 번들 파일(`editor.bundle.js`, `converter.bundle.js`)마다 `Framework`의 코드가 복제되어 들어갑니다. 자바스크립트 런타임 입장에서 이 두 코드는 **서로 다른 물리적 모듈**로 취급되므로, 각각 별도의 실행 컨텍스트와 메모리 공간을 갖게 됩니다.

따라서 모듈 시스템의 스코프를 넘어선 **전역 공간(Global Scope)**을 통한 상태 공유가 필요했습니다.

## 3. 해결 전략: Global Scope 활용

### 1차 접근: 전역 객체(globalThis) 사용
브라우저와 Node.js 환경 모두를 아우를 수 있는 표준인 `globalThis`에 인스턴스를 저장하기로 했습니다.

```typescript
// 단순히 문자열 키를 사용한다면?
globalThis['MY_FRAMEWORK_INSTANCE'] = new Framework();
```

하지만 단순히 문자열 키(`string key`)를 사용하는 것은 다음과 같은 위험이 있습니다.
* **이름 충돌:** 다른 라이브러리나 레거시 코드에서 우연히 같은 이름을 사용할 경우 덮어씌워질 위험이 있음.
* **전역 오염:** `Object.keys(window)` 등으로 조회했을 때 노출되어, 의도치 않은 접근이나 수정이 발생할 수 있음.

### 2차 접근: Symbol.for() 활용 (최종 솔루션)
이 문제를 해결하기 위해 **`Symbol.for()`**를 사용했습니다.

* **Namespace 격리:** Symbol은 일반 문자열 키와 다른 레이어에 저장되므로, 일반적인 전역 변수 접근으로 오염될 일이 없습니다.
* **Cross-Realm 공유:** `Symbol()`은 호출할 때마다 매번 다른 값을 만들지만, `Symbol.for('key')`는 **전역 심볼 레지스트리**를 통해 키가 같으면 동일한 심볼 객체를 반환합니다. 즉, **번들이 달라도 같은 심볼을 가리킬 수 있습니다.**

## 4. 구현 코드 (Implementation)

기존의 싱글톤 레지스트리 패턴에 `globalThis`와 `Symbol.for`를 적용한 구현입니다.

### SingletonRegistry.ts

```typescript
// 1. 전역에서 유일성을 보장하기 위한 Symbol 키 생성
// 충돌 방지를 위해 회사 도메인 등을 포함한 긴 네이밍 권장
const CONSTRUCTORS_KEY = Symbol.for('my-org.framework.registry.constructors');
const SINGLETONS_KEY = Symbol.for('my-org.framework.registry.singletons');

// 2. 전역 객체 타입 정의 (TypeScript)
type GlobalWithRegistry = typeof globalThis & {
  [CONSTRUCTORS_KEY]?: Map<string, new (...args: any[]) => any>;
  [SINGLETONS_KEY]?: Map<string, any>;
};

// 3. 전역 맵 접근 헬퍼 (초기화 로직 포함)
function getGlobalSingletons(): Map<string, any> {
  const g = globalThis as GlobalWithRegistry;
  if (!g[SINGLETONS_KEY]) {
    g[SINGLETONS_KEY] = new Map();
  }
  return g[SINGLETONS_KEY]!;
}

// ... 생성자 맵 접근 함수도 동일한 방식 ...

export namespace SingletonRegistry {
  export const register = (name: string, constructor: new (...args: any[]) => any) => {
    // 로컬 변수가 아닌 전역 심볼 맵에 저장
    getGlobalConstructors().set(name, constructor);
  };

  export const resolve = (name: string) => {
    const singletons = getGlobalSingletons();
    
    // 이미 생성된 인스턴스가 전역 맵에 있는지 확인
    if (!singletons.has(name)) {
      const constructors = getGlobalConstructors();
      const constructor = constructors.get(name);
      
      if (!constructor) {
        throw new Error(`Singleton ${name} is not registered`);
      }
      
      // 인스턴스 생성 후 전역 맵에 저장 -> 다른 번들에서도 이 인스턴스를 보게 됨 
      singletons.set(name, new constructor());
    }

    return singletons.get(name);
  };
}
```

이렇게 구현하면 `Editor` 번들에서 먼저 `resolve`를 호출해 인스턴스를 만들면, 나중에 로드된 `Converter` 번들에서도 `globalThis`의 심볼 키를 통해 **동일한 인스턴스**를 찾아 반환하게 됩니다.

## 5. 주의사항 및 한계 (Trade-offs)

이 방식은 유용한 "탈출구(Escape Hatch)"이지만, 몇 가지 주의할 점이 있습니다.

### 1) `instanceof` 체크 불가
서로 다른 번들에서 로드된 클래스는 내용은 같아도 자바스크립트 엔진상 **다른 생성자 함수**입니다. 따라서 `resolve()`로 가져온 객체에 대해 `instanceof` 검사를 하면 `false`가 나올 수 있습니다.
* **해결:** 타입 체크가 필요하다면 `instanceof` 대신 **Duck Typing**이나 공통 **Interface**를 사용해야 합니다.

### 2) 버전 관리 (Version Mismatch)
만약 `Editor`는 Framework v1.0을, `Converter`는 Framework v2.0을 번들링하고 있다면 런타임 에러가 발생할 수 있습니다. (v1 인스턴스가 전역에 있는데 v2 메서드를 호출하는 경우 등)
* **해결:** 모든 패키지가 동일한 버전의 Framework를 사용하도록 CI 단계에서 엄격하게 관리하거나, 심볼 키에 버전을 명시(`Symbol.for('...v1')`)하여 격리해야 합니다.

### 3) 테스트 격리
단위 테스트(Jest/Vitest) 실행 시 `globalThis`가 오염되어 테스트 간 간섭이 발생할 수 있습니다. `afterEach` 등에서 전역 심볼 맵을 초기화해주는 작업이 필요합니다.

## 6. 결론

NPM 패키지 배포 시 번들링 전략에 따라 싱글톤 패턴이 깨지는 문제는 흔히 발생할 수 있습니다. 가장 정석적인 방법은 `peerDependencies`를 사용하여 호스트가 단일 버전을 설치하게 하는 것이지만, 배포 및 사용 편의성을 위해 번들링이 필수적인 상황이라면 **`globalThis`와 `Symbol.for`를 활용한 전역 레지스트리 패턴**이 훌륭한 해결책이 될 수 있습니다.

이 패턴은 React, Styled-components 등 유명 라이브러리들에서도 런타임 환경의 제약을 극복하기 위해 내부적으로 사용하는 검증된 방식입니다. 다만, 사용 시 발생할 수 있는 사이드 이펙트(버전, 타입 체크)를 충분히 인지하고 적용해야 합니다.
0:{"buildId":"0SH4mtVfrBPx1prwmvYJL","rsc":["$","$1","c",{"children":[["$","$L2",null,{"posts":[{"title":"기획자도 할 수 있다: AI 생성 & 슬랙 버튼으로 완성하는 E2E 테스트 자동화 파이프라인","summary":"AI 생성 및 슬랙 버튼을 활용하여 E2E 테스트 자동화 파이프라인을 구축하고, 기술 장벽 없이 테스트에 기여할 수 있는 환경을 만드는 방법을 소개합니다.","tags":["E2E 테스트","자동화","AI","슬랙","ChatOps"],"date":"2025-12-22","id":"e2e-pipeline","content":"$3"},{"title":"E2E 테스트 vs 통합 테스트: 택일이 아닌 상호보완적 관계","date":"2025-12-22","summary":"E2E 테스트와 통합 테스트의 차이점을 명확히 정리하고, 두 테스트를 어떻게 조합해야 효율적인 테스트 전략을 수립할 수 있는지 설명합니다.","tags":["E2E","IntegrationTest","Testing","TestStrategy","상호보완"],"id":"integration-vs-e2e","content":"$4"},{"title":"🚀 Gemini CLI 완벽 가이드: 터미널에서 Gemini 모델 활용하기","summary":"Gemini CLI를 설치하고 설정하는 방법부터 Slash, At, Shell 명령어 사용법, 팁과 활용 예시까지 완벽하게 안내합니다.","tags":["Gemini","CLI","AI","터미널","개발"],"date":"2025-12-21","id":"gemini-cli-get-started","content":"$5"},{"title":"Giscus: 광고 없는 무료 댓글 시스템, 5분 만에 적용하기","summary":"Giscus는 GitHub Discussions API를 활용하여 광고 없이 깔끔한 디자인과 마크다운을 지원하는 무료 댓글 시스템으로, 개발 블로그에 쉽게 적용할 수 있습니다.","tags":["Giscus","댓글 시스템","GitHub Discussions","개발 블로그","무료"],"date":"2025-12-21","id":"giscus","content":"$6"},{"title":"GitHub Actions로 나만의 뉴스 브리핑 봇 만들기 (서버비 0원)","date":"2025-12-21","tags":["GitHub Actions","Automation","Slack Bot","RSS","Node.js"],"summary":"GitHub Actions의 Cron 스케줄러를 활용해 RSS 피드를 주기적으로 크롤링하고, 새로운 소식을 슬랙으로 전송하는 봇을 만드는 과정을 소개합니다.","id":"rss-news-bot-automation","content":"$7"},{"title":"[Tip] RSS란 무엇인가? 내 기술 블로그에 RSS 달고 Feedly로 구독하기","date":"2025-12-21","tags":["RSS","Blog","Tip"],"summary":"RSS의 개념과 GitHub Pages 블로그에 RSS를 적용하는 방법, Feedly 사용법을 알아봅니다.","id":"rss","content":"$8"},{"title":"Datadog vs Sentry: 우리 팀에 맞는 모니터링 툴은 무엇일까?","summary":"Datadog과 Sentry의 특징과 장단점을 비교하여 팀의 상황에 맞는 최적의 모니터링 도구를 선택하는 방법을 알아봅니다.","tags":["Datadog","Sentry","Monitoring","APM","RUM"],"date":"2025-12-21","id":"sentry-vs-datadog","content":"$9"},{"title":"Next.js App Router: useSuspenseQuery 서버 행(Hanging) 이슈 해결","date":"2025-12-20","tags":["Next.js","React Query","App Router"],"summary":"App Router에서 useSuspenseQuery 사용 시 발생하는 서버 행 현상의 원인을 파헤치고 next/dynamic을 통한 해결책을 제시합니다.","id":"app-router-useSuspenseQuery","content":"$a"},{"title":"프론트엔드 OOP와 FP 조화: 실무 적용 완벽 가이드","summary":"프론트엔드 개발에서 객체 지향 프로그래밍(OOP)과 함수형 프로그래밍(FP)을 조화롭게 사용하여 효율적인 아키텍처를 구축하는 방법을 알아봅니다.","tags":["frontend","OOP","FP","architecture","javascript"],"date":"2025-12-20","id":"frontend-oop-fp","content":"$b"},{"title":"가상화(Virtualization) 도입, 과연 정답일까? (feat. content-visibility)","summary":"가상화의 성능상 이점과 UX상의 단점을 살펴보고, content-visibility를 이용한 대안을 제시합니다.","tags":["virtualization","performance","css","content-visibility","frontend"],"date":"2025-12-20","id":"scroll-virtualization","content":"$c"},{"title":"NPM 패키지 분리 환경에서 싱글톤(Singleton) 유지하기: globalThis와 Symbol.for의 활용","summary":"물리적으로 분리된 번들 환경에서 globalThis와 Symbol.for를 활용하여 싱글톤 인스턴스를 안전하게 공유하는 방법을 설명합니다.","tags":["NPM","Singleton","globalThis","Symbol.for","JavaScript"],"date":"2025-12-20","id":"singleton-in-package","content":"$d"},{"title":"Folder Structure Test Post","date":"2020-12-21","tags":["Test","Structure"],"summary":"This is a test post to verify folder-based structure and image loading.","id":"folder-test-post","content":"\nThis is a post inside a folder.\n\nHere is an image:\n![Test Image](./image.png)\n\nAnd some text below.\n\n"}]}],["$Le"],"$Lf"]}],"loading":null,"isPartial":false}
e:["$","script","script-0",{"src":"/_next/static/chunks/cff909f88976765f.js","async":true}]
f:["$","$L10",null,{"children":["$","$11",null,{"name":"Next.MetadataOutlet","children":"$@12"}]}]
12:null
